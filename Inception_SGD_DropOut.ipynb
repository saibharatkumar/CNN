{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_SGD_DropOut.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6maC76SmhMtE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncO9STxrhNcu",
        "outputId": "d30eac94-de93-457b-f4fd-e761c7e8fa2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaSb6pj9hO1p"
      },
      "source": [
        "y_proc=np.zeros((50000,100))\n",
        "for i in range(0,50000):\n",
        "    y_proc[i][y_train[i][0]]=1\n",
        "y_test_proc=np.zeros((10000,100))\n",
        "for i in range(0,10000):\n",
        "    y_test_proc[i][y_test[i][0]]=1\n",
        "y_proc.shape\n",
        "input_shape=(32,32,3)\n",
        "y_test_proc[0]\n",
        "x_train=x_train.astype('float')/255\n",
        "x_test=x_test.astype('float')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tijJCVF5wq-"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMgnjpX5hQYW"
      },
      "source": [
        "inputs = keras.Input(shape=input_shape)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(inputs)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "#Inception1\n",
        "\n",
        "\n",
        "conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_2 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "#Inception2\n",
        "\n",
        "conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "#Inception3\n",
        "conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "conv_11 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_12 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_21 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_22 = layers.Conv2D(32, (3,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "x = layers.concatenate([conv_11,conv_12,conv_3,conv_4,conv_21,conv_22], axis=3)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "# conv_11 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_12 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_21 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_22 = layers.Conv2D(32, (3,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "#end\n",
        "\n",
        "# x = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "\n",
        "\n",
        "\n",
        "# x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.AveragePooling2D(4)(x)\n",
        "x=layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "outputs = layers.Dense(100, activation='softmax')(x)\n",
        "\n",
        "inception_net_model = keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcmEIKHFhTJN",
        "outputId": "0269497b-d467-4e6b-a24c-7e1af0d75bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inception_net_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 30, 30, 32)   896         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 32)   9248        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 26, 26, 32)   9248        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 26, 26, 32)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 24, 24, 32)   9248        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 22, 22, 32)   9248        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 20, 20, 32)   9248        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20, 20, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 20, 20, 32)   1056        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 20, 20, 32)   9248        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 20, 20, 32)   1056        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 32)   0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 20, 20, 32)   9248        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 20, 20, 32)   9248        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 20, 20, 32)   1056        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 20, 20, 32)   1056        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 20, 128)  0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 20, 20, 128)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 20, 20, 32)   4128        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 20, 20, 32)   4128        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 20, 20, 128)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 20, 20, 32)   4128        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 20, 20, 32)   4128        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 20, 20, 128)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 20, 20, 128)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 20, 20, 32)   4128        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 20, 20, 32)   9248        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 20, 20, 128)  0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 20, 20, 32)   4128        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 20, 20, 32)   3104        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 20, 20, 32)   7200        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 20, 20, 32)   4128        max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 20, 20, 32)   4128        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 20, 20, 32)   3104        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 20, 20, 32)   3104        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 20, 20, 192)  0           conv2d_26[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 20, 20, 192)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 18, 18, 32)   55328       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 64)   18496       conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 64)     0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          262400      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          25700       dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 543,012\n",
            "Trainable params: 543,012\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ne6LmsihVnf",
        "outputId": "407d7436-8a4c-404a-83a5-259151ca92e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "tensor_board = tf.keras.callbacks.TensorBoard(log_dir='tensorboard',histogram_freq=1)\n",
        "inception_net_model.compile(optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3,min_delta=0.005)\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='inception_sgd_dropout.hdf5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "# inception_net_model.fit(x_train,y_proc,batch_size=200,validation_data=(x_test,y_test_proc),epochs=50,callbacks=[callback,model_checkpoint_callback])\n",
        "output=inception_net_model.fit_generator(datagen.flow(x_train,y_proc,batch_size = 200), epochs = 100, validation_data = (x_test,y_test_proc),callbacks = [tensor_board,callback,model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-0b0cc2f2c4c8>:14: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "  1/250 [..............................] - ETA: 0s - loss: 4.6190 - acc: 0.0050WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "  2/250 [..............................] - ETA: 27s - loss: 4.6127 - acc: 0.0100WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0566s vs `on_train_batch_end` time: 0.1587s). Check your callbacks.\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 4.4133 - acc: 0.0322 - val_loss: 4.0491 - val_acc: 0.0800\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 3.8837 - acc: 0.1045 - val_loss: 3.6068 - val_acc: 0.1512\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 3.5424 - acc: 0.1612 - val_loss: 3.3347 - val_acc: 0.1987\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 3.3409 - acc: 0.1940 - val_loss: 3.2534 - val_acc: 0.2089\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 3.1521 - acc: 0.2306 - val_loss: 3.0317 - val_acc: 0.2525\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 3.0160 - acc: 0.2541 - val_loss: 2.9775 - val_acc: 0.2635\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.9006 - acc: 0.2769 - val_loss: 2.8819 - val_acc: 0.2821\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.8030 - acc: 0.2943 - val_loss: 2.6742 - val_acc: 0.3225\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.7036 - acc: 0.3164 - val_loss: 2.6499 - val_acc: 0.3219\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 31s 122ms/step - loss: 2.6239 - acc: 0.3293 - val_loss: 2.5835 - val_acc: 0.3481\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.5399 - acc: 0.3486 - val_loss: 2.6044 - val_acc: 0.3449\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.4748 - acc: 0.3613 - val_loss: 2.6484 - val_acc: 0.3374\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 2.4187 - acc: 0.3706 - val_loss: 2.5941 - val_acc: 0.3507\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.3711 - acc: 0.3827 - val_loss: 2.4602 - val_acc: 0.3702\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.3200 - acc: 0.3913 - val_loss: 2.3818 - val_acc: 0.3848\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.2852 - acc: 0.4011 - val_loss: 2.3566 - val_acc: 0.3892\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.2354 - acc: 0.4143 - val_loss: 2.3370 - val_acc: 0.3949\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.2011 - acc: 0.4179 - val_loss: 2.3916 - val_acc: 0.3865\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.1673 - acc: 0.4251 - val_loss: 2.2964 - val_acc: 0.4049\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.1221 - acc: 0.4345 - val_loss: 2.2691 - val_acc: 0.4124\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 2.0906 - acc: 0.4411 - val_loss: 2.2609 - val_acc: 0.4118\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.0598 - acc: 0.4506 - val_loss: 2.2403 - val_acc: 0.4197\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.0323 - acc: 0.4549 - val_loss: 2.1292 - val_acc: 0.4451\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 2.0100 - acc: 0.4609 - val_loss: 2.2030 - val_acc: 0.4272\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.9698 - acc: 0.4675 - val_loss: 2.1648 - val_acc: 0.4360\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.9611 - acc: 0.4729 - val_loss: 2.2524 - val_acc: 0.4150\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.9405 - acc: 0.4740 - val_loss: 2.3251 - val_acc: 0.4144\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.9086 - acc: 0.4812 - val_loss: 2.2298 - val_acc: 0.4238\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.8929 - acc: 0.4861 - val_loss: 2.1119 - val_acc: 0.4496\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.8728 - acc: 0.4895 - val_loss: 2.1438 - val_acc: 0.4405\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.8334 - acc: 0.5001 - val_loss: 2.0985 - val_acc: 0.4534\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.8316 - acc: 0.4980 - val_loss: 2.1525 - val_acc: 0.4472\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.8191 - acc: 0.5006 - val_loss: 2.1366 - val_acc: 0.4448\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.7941 - acc: 0.5099 - val_loss: 2.1788 - val_acc: 0.4394\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.7632 - acc: 0.5105 - val_loss: 2.1203 - val_acc: 0.4507\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.7416 - acc: 0.5180 - val_loss: 2.0441 - val_acc: 0.4703\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.7474 - acc: 0.5169 - val_loss: 2.0320 - val_acc: 0.4676\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.7142 - acc: 0.5237 - val_loss: 2.0428 - val_acc: 0.4700\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.7105 - acc: 0.5269 - val_loss: 2.0289 - val_acc: 0.4700\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.6857 - acc: 0.5323 - val_loss: 2.1349 - val_acc: 0.4517\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.6815 - acc: 0.5343 - val_loss: 2.0560 - val_acc: 0.4648\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.6548 - acc: 0.5403 - val_loss: 2.0996 - val_acc: 0.4593\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.6612 - acc: 0.5369 - val_loss: 2.0876 - val_acc: 0.4632\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.6355 - acc: 0.5442 - val_loss: 2.0045 - val_acc: 0.4811\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.6220 - acc: 0.5461 - val_loss: 2.0043 - val_acc: 0.4791\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.6062 - acc: 0.5496 - val_loss: 2.1038 - val_acc: 0.4659\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.5870 - acc: 0.5544 - val_loss: 1.9410 - val_acc: 0.4921\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.5857 - acc: 0.5555 - val_loss: 1.9860 - val_acc: 0.4856\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.5875 - acc: 0.5558 - val_loss: 1.9633 - val_acc: 0.4874\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.5621 - acc: 0.5624 - val_loss: 2.1278 - val_acc: 0.4660\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.5428 - acc: 0.5675 - val_loss: 2.0537 - val_acc: 0.4768\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.5264 - acc: 0.5708 - val_loss: 2.1244 - val_acc: 0.4735\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.5249 - acc: 0.5681 - val_loss: 2.0227 - val_acc: 0.4934\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.5266 - acc: 0.5697 - val_loss: 2.0152 - val_acc: 0.4869\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.5153 - acc: 0.5719 - val_loss: 2.0034 - val_acc: 0.4835\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4934 - acc: 0.5792 - val_loss: 1.9650 - val_acc: 0.4940\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 31s 123ms/step - loss: 1.4868 - acc: 0.5791 - val_loss: 2.0284 - val_acc: 0.4918\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4721 - acc: 0.5820 - val_loss: 1.9978 - val_acc: 0.4906\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4734 - acc: 0.5810 - val_loss: 1.9848 - val_acc: 0.4906\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4630 - acc: 0.5850 - val_loss: 1.9771 - val_acc: 0.4952\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4521 - acc: 0.5884 - val_loss: 1.9371 - val_acc: 0.5089\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 32s 130ms/step - loss: 1.4393 - acc: 0.5906 - val_loss: 2.0038 - val_acc: 0.4907\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 32s 126ms/step - loss: 1.4398 - acc: 0.5897 - val_loss: 1.9989 - val_acc: 0.4869\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4292 - acc: 0.5928 - val_loss: 1.9781 - val_acc: 0.4928\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.4125 - acc: 0.5958 - val_loss: 1.8831 - val_acc: 0.5138\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4148 - acc: 0.5946 - val_loss: 2.0723 - val_acc: 0.4767\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.4075 - acc: 0.5954 - val_loss: 1.9780 - val_acc: 0.4947\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 31s 126ms/step - loss: 1.4009 - acc: 0.5991 - val_loss: 2.0412 - val_acc: 0.4932\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 31s 126ms/step - loss: 1.3900 - acc: 0.6000 - val_loss: 1.9584 - val_acc: 0.4983\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3927 - acc: 0.6010 - val_loss: 1.9385 - val_acc: 0.5091\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.3659 - acc: 0.6087 - val_loss: 2.0146 - val_acc: 0.4952\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3811 - acc: 0.6058 - val_loss: 1.9019 - val_acc: 0.5133\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 31s 126ms/step - loss: 1.3587 - acc: 0.6086 - val_loss: 1.8938 - val_acc: 0.5117\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.3539 - acc: 0.6126 - val_loss: 1.9795 - val_acc: 0.5029\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3461 - acc: 0.6114 - val_loss: 1.9814 - val_acc: 0.5053\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3414 - acc: 0.6153 - val_loss: 1.9948 - val_acc: 0.5019\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3270 - acc: 0.6172 - val_loss: 1.9202 - val_acc: 0.5169\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3171 - acc: 0.6194 - val_loss: 1.9401 - val_acc: 0.5165\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3235 - acc: 0.6213 - val_loss: 1.9353 - val_acc: 0.5145\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3152 - acc: 0.6220 - val_loss: 1.9393 - val_acc: 0.5087\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3015 - acc: 0.6236 - val_loss: 1.9407 - val_acc: 0.5142\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.3086 - acc: 0.6226 - val_loss: 2.0590 - val_acc: 0.4935\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.3046 - acc: 0.6249 - val_loss: 1.9016 - val_acc: 0.5222\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.2916 - acc: 0.6273 - val_loss: 1.8926 - val_acc: 0.5172\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.2743 - acc: 0.6311 - val_loss: 1.9998 - val_acc: 0.5043\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.2920 - acc: 0.6278 - val_loss: 1.9349 - val_acc: 0.5124\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.2824 - acc: 0.6265 - val_loss: 2.1043 - val_acc: 0.4895\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.2583 - acc: 0.6348 - val_loss: 1.9384 - val_acc: 0.5097\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 31s 124ms/step - loss: 1.2564 - acc: 0.6343 - val_loss: 1.9508 - val_acc: 0.5170\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.2640 - acc: 0.6330 - val_loss: 2.1017 - val_acc: 0.4881\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 31s 125ms/step - loss: 1.2542 - acc: 0.6339 - val_loss: 2.0012 - val_acc: 0.5135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_4PLK1liBTW",
        "outputId": "a7292a3b-68da-462e-c3a1-d46eecce667e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "y_pred=inception_net_model.predict(x_test)\n",
        "# tf.one_hot(y_pred)\n",
        "# y_pred=np.where(y_pred[0]=max(y_pred[0],1,0))\n",
        "y_pred_proc=np.zeros((10000,100))\n",
        "for i in range(0,10000):\n",
        "    y_pred_proc[i][np.argmax(y_pred[i])]=1\n",
        "print(\"Precision: \"+ str(precision_score(y_test_proc, y_pred_proc, average='weighted')))\n",
        "print(\"Recall: \"+ str(recall_score(y_test_proc, y_pred_proc, average='weighted')))\n",
        "print(\"Accuracy: \"+ str(accuracy_score(y_test_proc, y_pred_proc)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.5454160681545852\n",
            "Recall: 0.5135\n",
            "Accuracy: 0.5135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7YI5kGj6oDz",
        "outputId": "85a48343-4771-46b5-ec24-55e3e7fd87ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.legend(['Training Accuracy','Testing Accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0e490d3668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hb-imTV6oHW",
        "outputId": "de201b34-7a27-4ea5-cfa1-a17ee2279da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.legend(['Training loss','Testing loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0e490897b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubF1Xwt6JCFj",
        "outputId": "247b27a9-a092-4bc2-f3b7-29a9a46e8063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "y_proc=np.zeros((50000,100))\n",
        "for i in range(0,50000):\n",
        "    y_proc[i][y_train[i][0]]=1\n",
        "y_test_proc=np.zeros((10000,100))\n",
        "for i in range(0,10000):\n",
        "    y_test_proc[i][y_test[i][0]]=1\n",
        "y_proc.shape\n",
        "input_shape=(32,32,3)\n",
        "y_test_proc[0]\n",
        "x_train=x_train.astype('float')/255\n",
        "x_test=x_test.astype('float')/255\n",
        "\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(inputs)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "x = layers.Conv2D(32, 3, activation='elu')(x)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "#Inception1\n",
        "\n",
        "\n",
        "conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_2 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "#Inception2\n",
        "\n",
        "conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_1)\n",
        "# conv_1 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_2 = layers.Conv2D(32, (1,7), padding='same', activation='elu')(conv_2)\n",
        "# conv_2 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "#Inception3\n",
        "conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "conv_11 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_12 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "conv_21 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_22 = layers.Conv2D(32, (3,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "x = layers.concatenate([conv_11,conv_12,conv_3,conv_4,conv_21,conv_22], axis=3)\n",
        "\n",
        "x = layers.Dropout(0.01)(x)\n",
        "\n",
        "# conv_1 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_1 = layers.Conv2D(32, (3,3), padding='same', activation='elu')(conv_1)\n",
        "# conv_11 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_12 = layers.Conv2D(32, (7,1), padding='same', activation='elu')(conv_1)\n",
        "\n",
        "# conv_2 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "# conv_21 = layers.Conv2D(32, (1,3), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_22 = layers.Conv2D(32, (3,1), padding='same', activation='elu')(conv_2)\n",
        "\n",
        "# conv_3 = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "# conv_3 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(conv_3)\n",
        "\n",
        "# conv_4 = layers.Conv2D(32, (1,1), padding='same', activation='elu')(x)\n",
        "\n",
        "# x = layers.concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
        "\n",
        "#end\n",
        "\n",
        "# x = layers.MaxPool2D((3,3), strides=(1,1), padding='same')(x)\n",
        "\n",
        "\n",
        "\n",
        "# x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.AveragePooling2D(4)(x)\n",
        "x=layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "outputs = layers.Dense(100, activation='softmax')(x)\n",
        "\n",
        "inception_net_model = keras.Model(inputs, outputs)\n",
        "\n",
        "inception_net_model.load_weights('../weights/inception_sgd_dropout.hdf5')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "y_pred=inception_net_model.predict(x_test)\n",
        "# tf.one_hot(y_pred)\n",
        "# y_pred=np.where(y_pred[0]=max(y_pred[0],1,0))\n",
        "y_pred_proc=np.zeros((10000,100))\n",
        "for i in range(0,10000):\n",
        "    y_pred_proc[i][np.argmax(y_pred[i])]=1\n",
        "print(\"Precision: \"+ str(precision_score(y_test_proc, y_pred_proc, average='weighted')))\n",
        "print(\"Recall: \"+ str(recall_score(y_test_proc, y_pred_proc, average='weighted')))\n",
        "print(\"Accuracy: \"+ str(accuracy_score(y_test_proc, y_pred_proc)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 11s 0us/step\n",
            "Precision: 0.5411781656869528\n",
            "Recall: 0.5222\n",
            "Accuracy: 0.5222\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}